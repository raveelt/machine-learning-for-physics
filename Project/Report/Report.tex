\documentclass[]{article}

\usepackage{fancyhdr}  % Include the package for custom headers and footers

\pagestyle{fancy}  % Change the page style to fancy to apply custom headers/footers
\fancyhf{}  % Clear all header and footer fields to start fresh
\fancyhead[R]{\thepage}  % Place the page number in the top right corner of the header
\renewcommand{\headrulewidth}{0pt}  % Remove the header rule line
\usepackage{pdflscape}
\usepackage{pdfpages}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{colortbl}
\usepackage{booktabs}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
%opening


\newenvironment{changemargin}[2]{%
	\begin{list}{}{%
			\setlength{\topsep}{0pt}%
			\setlength{\leftmargin}{#1}%
			\setlength{\rightmargin}{#2}%
			\setlength{\listparindent}{\parindent}%
			\setlength{\itemindent}{\parindent}%
			\setlength{\parsep}{\parskip}%
		}%
		\item[]}{\end{list}}
	

\title{Neural Network Classification of Top Quark Production at the Large Hadron Collider }
\author{Raveel Tejani}
\date{\parbox{\linewidth}{\centering%
		\today\endgraf\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
		\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
		PHYS 310 \endgraf\bigskip
		University of British Columbia}}



\begin{document}

\maketitle
\thispagestyle{empty}
\clearpage

\tableofcontents 
\thispagestyle{empty}
\clearpage

\listoftables
\thispagestyle{empty}
\clearpage
             
\listoffigures
\thispagestyle{empty}
\clearpage     

\section{Introduction}

At the Large Hadron Collider (LHC), where protons are collided at a staggering rate of 40 MHz across various points within the LHC ring, the ATLAS experiment plays a pivotal role as a general-purpose detector at one of these collision sites. It precisely tracks particles emitted from these collisions, an essential task for understanding fundamental physics. The integration of machine learning, specifically neural networks, is instrumental in distinguishing between different physics processes: "signals" and the more prevalent "background" events. Achieving accurate discrimination between these is crucial due to the relatively rare occurrence of signal events. The focus of this project was to explore several key objectives within the context of high-energy physics:

\begin{enumerate}
 \item Training a Classifier: Develop a neural network classifier to accurately distinguish between ttZ (the production of a pair of top quarks associated with a Z boson) and WZ (the production of a W and a Z boson) events. This distinction is critical as both ttZ and WZ can produce similar detector-level features, yet represent different underlying physics processes.
\item Feature Selection: Experiment with the addition and removal of various detector-level features to evaluate how each alteration affects the classifier's performance. This analysis helps in understanding which features are most predictive and thus critical for accurate event classification.
 \item Optimization of Neural Network: Enhance the architecture and training parameters of the neural network to maximize its performance in classifying ttZ and WZ events. This includes adjustments in network structure, learning rates, and other hyperparameters to refine the model efficacy.
 \item Feature Ranking: Determine and rank the importance of these features in the neural network to prioritize data collection and processing strategies at the detector level.

\end{enumerate}
To accomplish these goals, simulated data samples of ttZ and WZ events, produced using Monte Carlo simulations, were utilized to train the neural network. This training enables the classifier to learn the distinctive patterns of each event type. Once optimized, the classifier is then applied to actual recorded data from the LHC, using its outputs for further statistical analysis and insights. This project not only advances the accuracy and efficiency of particle identification at the ATLAS experiment but also contributes significantly to the broader field of particle physics, enhancing our understanding of particle interactions and the fundamental forces of nature.

\clearpage
\section{Methods}

The initial phase of the project involved utilizing a predefined neural network (NN) model, constructed using Keras's Sequential API, for the classification of ttZ and WZ events. The base model was configured to operate with a subset of features, specifically 9 out of a possible 18 features, selected based on prior analyses which identified them as significant. 
We will perform the following steps to hopefully enhance the model's performance:

\begin{figure}[ht]

	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=.45\linewidth]{base_model/base_loss.pdf}
		\caption{Loss reduction as a function of epochs}
	\end{subfigure}%
	\vspace{0.2cm} % Adds space between the rows
	
	\begin{subfigure}{\textwidth}
	\centering
		\includegraphics[height=.45\linewidth]{base_model/base_accuracy.pdf}
		\caption{Accuracy performance as a function of epochs}
	
	\end{subfigure}
	\vspace{0.2cm} % Adds space between the rows
	
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[height=.45\linewidth]{base_model/base_NNout.pdf}
		\caption{Probability distribution of test and train cases, based on trained Neural network}
	\end{subfigure}
	
	\caption{Perfromance of The Base Neural Network Model Using Base Feature Selection. (a) Loss curves for the training and validation datasets, demonstrating model convergence. (b) Accuracy scores for the training and validation datasets, reflecting model effectiveness. (c) NN output distributions for both training and testing datasets, highlighting the model's differentiation between signal and background classes.}
	\label{fig:base_model_plots}
\end{figure}


\begin{enumerate}
\item \textbf{Feature Selection:}
To enhance the model's performance, a Sequential Feature Selector (SFS) was employed to methodically identify the most impactful features. This process resulted in two new feature sets: the "best" feature list comprising 11 of the 18 total features, and a "small" feature list which achieved comparable accuracy with only 7 out of 10 features. These subsets were chosen based on their ability to optimize the predictive accuracy of the models while minimizing complexity. Subsequent to feature selection, a comparative analysis was conducted using the base model structure with three different sets of features: the original base feature list, the newly identified best feature list, and the small feature list. This comparison was aimed at determining the impact of each feature set on model performance in terms of accuracy and efficiency.

\item \textbf{Parameter Optimization via GridSearchCV:}
Following the feature comparison, GridSearchCV was implemented to systematically explore and optimize several hyperparameters for each model variant (base, best feature list, and small feature list). Each of the three feature sets was then evaluated using their respective optimized models, as determined by the GridSearchCV results. The effectiveness of each model was assessed based on the optimized feature list and model parameters, focusing on classification accuracy and computational efficiency.

\item \textbf{Feature Importance Analysis:}
Finally, to understand the contribution of individual features within the optimized models, a permutation feature importance analysis was performed. This method involved systematically altering the values of each feature in the dataset and observing the resultant impact on model performance. This analysis helped to highlight which features were most critical to the model’s predictive capabilities, providing insights into the underlying data structure and the physics phenomena being modeled.
\end{enumerate}

%The methodological approach adopted in this study allowed for a comprehensive evaluation of feature selection techniques, hyperparameter optimization, and the relative importance of individual features, culminating in a robust analysis of neural network models for classifying high-energy physics events.




\clearpage
\section{Results}

%Address all project questions and support your findings with appropriate graphs. Present
%clearly defined figures with good layout. Make sure data interpretation is easy to infer
%from figures and tables. Throughout the results, employ good practices of ML such as
%cross-validation and hyperparameter optimization.


\subsection{Feature Selection}


In this subsection, we present our findings from applying Sequential Feature Selection (SFS) to our dataset. SFS, while powerful, is notably computationally intensive as it involves multiple iterations over the feature list. The process begins with a model devoid of any features, progressively incorporating features based on their contribution to performance enhancement. Given our dataset includes 18 features, this amounts to 171 evaluations:

$$18 + 17 + ....  + 1 = \frac{18 \times 19}{2} = 171 $$

Additionally, we employ cross-validation during each evaluation to enhance the robustness of our findings, leading to a total of 
$171 \times 5 =855$ model fits. To manage the computational demands, we selectively use smaller data subsets—10,000 and 30,000 samples—and execute SFS on these subsets. The implementation details can be found in Appendix \ref{code_feat_selection}. 

The outcomes, are summarized in Figure \ref{fig:SFS_results} and Table \ref{table:SFS_results}. This approach not only elucidates the efficacy of selected features but also helps in optimizing processing time.  Table \ref{table:SFS_results} outlines the features selected during each iteration and their corresponding average CV accuracy, illustrating how each feature contributes to the overall model performance. The results are directly related to plot (b) in Figure \ref{fig:SFS_results}, providing a detailed view of the feature selection impact within this specific subset.

We have opted to advance with three distinct feature lists for our analysis. The first list is the initially suggested base list, the second is the best-performing list as determined by the Sequential Feature Selector (SFS), and the third is the smallest list that maintains at least 80\% accuracy. The latter two lists are highlighted in green in Table \ref{table:SFS_results}. Utilizing the full dataset, we produced plots similar to those in Figure \ref{fig:base_model_plots} using the base NN architecure provided, and our findings are showcased in Figure \ref{fig:base_models}. The relevant code is documented in Appendix \ref{code_feat_comparison}.


	\begin{figure}[ht]
		\centering
		\begin{subfigure}{\textwidth}
			\centering
		\includegraphics[width=0.9\linewidth]{feature selection/feature_num_performance_10k.pdf}
		\caption{10 000 samples}
		\end{subfigure}
		
		\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{feature selection/feature_num_performance_30k.pdf}
		\caption{30 000 samples}
		\end{subfigure}
		\caption{Accuracy Performance of the Sequential Feature Selector on Two Data Subsets.}
		\label{fig:SFS_results}
	\end{figure}
	
	
\begin{landscape}
\begin{table}[]
	\centering
	\resizebox{0.8\columnwidth}{!}{%
	\begin{tabular}{@{}lr@{}}
		\toprule
		Average CV Score               & Feature Names                                                                                                                                                                                                                                                                                        \\ \midrule
		70.96\%                        & ('bjet\_1\_pt',)                                                                                                                                                                                                                                                                                     \\ \addlinespace[0.5em]
		73.81\%                        & ('bjet\_1\_pt', 'n\_jets')                                                                                                                                                                                                                                                                           \\ \addlinespace[0.5em]
		74.94\%                        & ('bjet\_1\_pt', 'n\_jets', 'n\_bjets')                                                                                                                                                                                                                                                               \\ \addlinespace[0.5em]
		76.82\%                        & ('jet\_1\_twb', 'bjet\_1\_pt', 'n\_jets', 'n\_bjets')                                                                                                                                                                                                                                                \\ \addlinespace[0.5em]
		79.78\%                        & ('jet\_1\_twb', 'jet\_2\_twb', 'bjet\_1\_pt', 'n\_jets', 'n\_bjets')                                                                                                                                                                                                                                 \\ \addlinespace[0.5em]
		79.44\%                        & ('jet\_3\_pt', 'jet\_1\_twb', 'jet\_2\_twb', 'bjet\_1\_pt', 'n\_jets', 'n\_bjets')                                                                                                                                                                                                                   \\ \addlinespace[0.5em]
		\rowcolor[HTML]{32CB00} 
		81.61\%                        & ('jet\_3\_pt', 'jet\_1\_twb', 'jet\_2\_twb', 'jet\_3\_twb', 'bjet\_1\_pt',   'n\_jets', 'n\_bjets')                                                                                                                                                                                                  \\ \addlinespace[0.5em]
		81.77\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_3\_pt', 'jet\_3\_eta', 'jet\_1\_twb', 'jet\_2\_twb', 'jet\_3\_twb',   'bjet\_1\_pt', 'n\_jets',\\ 'n\_bjets')\end{tabular}                                                                                                                                         \\ \addlinespace[0.5em]
		81.65\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_3\_pt', 'jet\_1\_eta', 'jet\_3\_eta', 'jet\_1\_twb', 'jet\_2\_twb',   'jet\_3\_twb', 'bjet\_1\_pt',\\ 'n\_jets', 'n\_bjets')\end{tabular}                                                                                                                          \\ \addlinespace[0.5em]
		81.84\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_3\_pt', 'jet\_1\_eta', 'jet\_3\_eta', 'jet\_1\_twb', 'jet\_2\_twb',   'jet\_3\_twb', 'bjet\_1\_pt',\\ 'n\_jets', 'n\_bjets', 'n\_leptons')\end{tabular}                                                                                                            \\ \addlinespace[0.5em]
		\rowcolor[HTML]{32CB00} 
		{\color[HTML]{000000} 81.88\%} & {\color[HTML]{000000} \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_3\_eta', 'jet\_1\_twb',   'jet\_2\_twb', 'jet\_3\_twb',\\ 'bjet\_1\_pt', 'n\_jets', 'n\_bjets', 'n\_leptons')\end{tabular}}                                                                       \\ \addlinespace[0.5em]
		81.78\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_3\_eta', 'jet\_1\_twb',   'jet\_2\_twb', 'jet\_3\_twb',\\ 'bjet\_1\_pt', 'lep\_1\_pt', 'n\_jets', 'n\_bjets',   'n\_leptons')\end{tabular}                                                                              \\ \addlinespace[0.5em]
		81.73\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta', 'jet\_3\_eta',   'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt', 'n\_jets',   'n\_bjets', 'n\_leptons')\end{tabular}                                                               \\ \addlinespace[0.5em]
		80.99\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta', 'jet\_3\_eta',   'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt', 'n\_jets',   'n\_bjets', 'n\_leptons', 'H\_T')\end{tabular}                                                       \\ \addlinespace[0.5em] 
		81.28\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta', 'jet\_3\_eta',   'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt', 'n\_jets',   'n\_bjets', 'n\_leptons', 'met\_met', 'H\_T')\end{tabular}                                           \\ \addlinespace[0.5em]
		81.59\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta', 'jet\_3\_eta',   'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt', 'lep\_2\_pt',   'n\_jets', 'n\_bjets', 'n\_leptons', 'met\_met', 'H\_T')\end{tabular}                             \\ \addlinespace[0.5em]
		80.72\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta', 'jet\_3\_eta',   'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt', 'lep\_2\_pt',   'lep\_3\_pt', 'n\_jets', 'n\_bjets', 'n\_leptons', 'met\_met', 'H\_T')\end{tabular}               \\ \addlinespace[0.5em]
		79.84\%                        & \begin{tabular}[c]{@{}l@{}}('jet\_1\_pt', 'jet\_2\_pt', 'jet\_3\_pt', 'jet\_1\_eta', 'jet\_2\_eta',   'jet\_3\_eta', 'jet\_1\_twb', 'jet\_2\_twb',\\ 'jet\_3\_twb', 'bjet\_1\_pt', 'lep\_1\_pt',   'lep\_2\_pt', 'lep\_3\_pt', 'n\_jets', 'n\_bjets', 'n\_leptons', 'met\_met', 'H\_T')\end{tabular} \\ \bottomrule
	\end{tabular}
	}
	\caption{Iterative Feature Selection and Corresponding Average Cross-Validation Accuracy Scores by Sequential Feature Selector (SFS) for the 30,000 Sample Subset.}
	\label{table:SFS_results}
\end{table}

\end{landscape}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{feature_comparison/feat-comparison.pdf}
	\caption{Performance Comparison of Neural Network Models Using Different Feature Lists. Top panels show loss curves for the base list, SFS best list, and smallest list with over $80\%$ accuracy across training and validation phases over 100 epochs. Middle panels depict corresponding accuracy values. Bottom panels illustrate NN output distributions for training and testing datasets, highlighting model behavior for signal and background classes.}
	\label{fig:base_models}
\end{figure}

\clearpage

\subsection{Parameter Optimization via GridSearchCV}

In this subsection, we detail our findings from using GridSearchCV on three feature lists identified previously. The optimization adjusted parameters including the number of nodes in three neural network layers, learning rate, and batch size, with three possible values for each of these five parameters, as shown in Table \ref{table:gridsearchCV_params}. Notably, parameters in Set 2 are those used in the base model. This exhaustive search, involving $3^7 = 2187$ fits due to the parameters, threefold cross-validation, and three feature sets, demanded significant computational resources, leading us to use a smaller dataset of 30,000 samples.

The results are presented in Table \ref{table:best_params_gridsearchCV}, which displays the best parameter configurations and their corresponding performances. Each configuration was evaluated through 3-fold cross-validation, and the 'Best Score' column indicates the average accuracy across the folds, identifying the most effective settings. We then applied these optimal parameters to generate the visualizations in Figure \ref{fig:best_models}, akin to those in Figure \ref{fig:base_models}. Relevant code is available in Appendices \ref{code_model_selection} and \ref{code_best_models}.

\begin{table}[h!]
	\centering
	\begin{tabular}{@{}lrrr@{}}
		\toprule
		Parameter            & Set 1  & Set 2  & Set 3  \\ \midrule
		Nodes: Dense Layer 1 & 25     & 50     & 100    \\
		Nodes: Dense Layer 2 & 12     & 25     & 50     \\
		Nodes: Dense Layer 3 & 5      & 10     & 15     \\
		Batch Size           & 100    & 150    & 300    \\
		Adam Learning Rate   & 0.002  & 0.0002 & 0.00002 \\
		\bottomrule   
	\end{tabular}
	\caption{Parameter configurations for GridSearchCV, listing sets of values for nodes in each dense layer, batch sizes, and learning rates. Configuration 2 corresponds to the parameters of the base model.} 
	\label{table:gridsearchCV_params}
\end{table}



\begin{table}[h!]
	\centering
	\begin{tabular}{@{}lrrr@{}}
		\toprule
		Parameters           & Base List & SRS: Best List & SRS: Best Small List \\ \midrule

		Nodes: Dense Layer 1 & 50        & 25             & 50                                                  \\
		Nodes: Dense Layer 2 & 12        & 25             & 50                                                  \\
		Nodes: Dense Layer 3 & 10        & 15             & 5                                                   \\
				Batch Size          & 300       & 100            & 150                                                 \\
		Adam Learning Rate   & 0.002     & 0.002          & 0.0002                                              \\
		Best Score           & 82.96\%   & 83.39\%        & 82.7\%  \\
		\bottomrule                                            
	\end{tabular}
	\caption{Optimized Parameter Sets and Corresponding Performance Scores from GridSearchCV for our Three Feature Lists.} 
	\label{table:best_params_gridsearchCV}
	
\end{table}




\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{best_model/best_models.pdf}
	\caption{Performance Comparison of Optimized Neural Network Models Using Different Feature Lists. This figure displays the outcomes of models individually optimized using GridSearchCV for the base list, the SFS best list, and the smallest list with over 80\% accuracy. The top panels illustrate loss curves for both training and validation phases over 100 epochs. The middle panels show the corresponding accuracy values, and the bottom panels provide NN output distributions for the training and testing datasets, emphasizing the model's differentiation between signal and background classes.}
	\label{fig:best_models}
\end{figure}

\clearpage

\subsection{Feature Importance Analysis}

In this subsection, we present our findings from conducting permutation feature importance analysis on the optimal models developed in the previous subsection. Permutation feature importance evaluates the impact of each feature on the model's performance by randomly shuffling individual feature values and observing the change in model accuracy. This process disrupts the relationship between the feature and the outcome, quantifying the importance of each feature based on the decrease in model performance. Our findings are summarized in Figure \ref{fig:best_models_feature_ranking}. This figure displays the relative importance of features across all three feature lists, highlighting how each feature contributes to model performance when utilizing the best parameters identified for each list.  The relevant code is documented in Appendix \ref{code_best_models}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{best_model/feature_importances.pdf}
	\caption{Feature Importances for Each Feature List Based on Optimized Model Parameters. }
	\label{fig:best_models_feature_ranking}
\end{figure}



\clearpage
\section{Discussion and Summary}

In this study, while we did not achieve a significant improvement in accuracy, we successfully demonstrated the ability to reduce the dimensionality of our feature space without compromising accuracy. Notably, our smallest feature list comprising only 7 features performed comparably to the base list of 9 features and the optimal list of 11 features identified by Sequential Feature Selector (SFS).

An interesting observation emerged from the feature importance analysis. Contrary to expectations, the ranking of features in the smallest list did not align perfectly with those in the best list derived from SFS. For example, the feature $\mathrm{jet\_1\_pt}$ was ranked higher in the best list's feature importance despite not being in the top 7 of the SFS selections. Additionally, the base model identified $\mathrm{H\_T}$ as the most crucial feature, a finding SFS did not recognize until the 14th iteration, as shown in Table \ref{table:SFS_results}. This discrepancy suggests that the forward iteration approach of SFS may not have been optimal, and exploring alternative methods such as backward elimination could potentially yield different insights into feature significance.

Although SFS did not fail (provided results comparable to the base model), it also did not furnish a significant enhancement in performance. The grid search over various parameters similarly did not yield a substantial increase in accuracy, with most results hovering around 80\%.


This study underscores the complexity of feature selection and the potential limitations of certain algorithms in capturing the most predictive features. Future work could explore more dynamic feature selection methods or hybrid approaches that combine forward and backward elimination to potentially uncover more effective feature combinations. Additionally, experimenting with different model architectures or more advanced machine learning algorithms might also lead to improvements in performance. Overall, the findings suggest a continued exploration into more nuanced aspects of feature selection and model optimization to better understand and enhance predictive accuracies in complex datasets.
\appendix

\clearpage
\section{Code: Base Model}

In this section, we provide the code used to implement the base model introduced at the beginning of this project. This code was used in generating the visualizations displayed in Figure \ref{fig:base_model_plots}.

\includepdf[pages=-]{base_model/base_model.pdf}

\section{Code: Feature Selection}\label{code_feat_selection}


In this section, we present the code utilized for the Sequential Feature Selector. This code facilitated the creation of the plots shown in Figure \ref{fig:SFS_results} and the data compiled in Table \ref{table:SFS_results}.

\includepdf[pages=-]{feature selection/feature_selection.pdf}

\section{Code: Feature Comparison}\label{code_feat_comparison}


In this section, we present code was utilized to generate the plots in Figure \ref{fig:base_models}, which compare the performance of the base neural network model across the three feature lists.

\includepdf[pages=-]{feature_comparison/feature_comparison.pdf}

\section{Code: Parameter Optimization via GridSearchCV}\label{code_model_selection}

In this section, you will find the code used for applying GridSearchCV to optimize model parameters. This code was instrumental in producing the data shown in Tables \ref{table:gridsearchCV_params} and \ref{table:best_params_gridsearchCV}.

\includepdf[pages=-]{model_selection/model_selection.pdf}

\section{Code: Best Models Performance and Feature Importance}\label{code_best_models}

In this section, the provided code was used to generate the plots in Figure \ref{fig:best_models}, which compare the performance of individually optimized neural network models across the three feature lists. Additionally, this code facilitated the analysis of permutation feature importance, as displayed in Figure \ref{fig:best_models_feature_ranking}.

\includepdf[pages=-]{best_model/best_models_code.pdf}

\end{document}
